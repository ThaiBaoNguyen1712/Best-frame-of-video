import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import tempfile
import os
from io import BytesIO
import gc

# Import tr·ª±c ti·∫øp ƒë·ªÉ tr√°nh l·ªói AttributeError: module 'mediapipe' has no attribute 'solutions'
try:
    import mediapipe as mp
    from mediapipe.python.solutions import face_detection as mp_face
    from mediapipe.python.solutions import pose as mp_pose
    from mediapipe.python.solutions import drawing_utils as mp_drawing
    USE_AI = True
except (ImportError, AttributeError):
    USE_AI = False

# --- C√ÅC H√ÄM X·ª¨ L√ù LOGIC ---

def calculate_sharpness(frame):
    """T√≠nh ƒë·ªô s·∫Øc n√©t b·∫±ng bi·∫øn thi√™n Laplacian"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    return cv2.Laplacian(gray, cv2.CV_64F).var()

def get_ai_scores(frame, face_model, pose_model):
    """Ch·∫•m ƒëi·ªÉm khu√¥n m·∫∑t v√† t∆∞ th·∫ø s·ª≠ d·ª•ng MediaPipe"""
    face_score = 0.0
    num_faces = 0
    pose_score = 0.0
    
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # 1. Ch·∫•m ƒëi·ªÉm khu√¥n m·∫∑t
    face_results = face_model.process(rgb_frame)
    if face_results.detections:
        num_faces = len(face_results.detections)
        face_score = np.mean([d.score[0] for d in face_results.detections])
    
    # 2. Ch·∫•m ƒëi·ªÉm t∆∞ th·∫ø (Pose) - Quan tr·ªçng cho dancer
    pose_results = pose_model.process(rgb_frame)
    if pose_results.pose_landmarks:
        lm = pose_results.pose_landmarks.landmark
        # T√≠nh ƒë·ªô m·ªü c·ªßa tay (ƒëi·ªÉm 15, 16) v√† ch√¢n (ƒëi·ªÉm 27, 28)
        arm_span = np.sqrt((lm[15].x - lm[16].x)**2 + (lm[15].y - lm[16].y)**2)
        leg_span = np.sqrt((lm[27].x - lm[28].x)**2 + (lm[27].y - lm[28].y)**2)
        # ƒêi·ªÉm pose cao khi c∆° th·ªÉ bung t·ªèa (extension)
        pose_score = min((arm_span + leg_span) * 1.5, 1.0)
        
    return face_score, num_faces, pose_score

def calculate_total_score(frame, face_model, pose_model):
    """T√≠nh ƒëi·ªÉm t·ªïng h·ª£p, ki·ªÉm tra an to√†n n·∫øu AI model kh√¥ng t·ªìn t·∫°i"""
    sharpness = calculate_sharpness(frame)
    norm_sharpness = min(sharpness / 800.0, 1.0)
    
    # Ki·ªÉm tra n·∫øu c·∫£ hai model ƒë·ªÅu s·∫µn s√†ng
    if USE_AI and face_model is not None and pose_model is not None:
        face_score, num_faces, pose_score = get_ai_scores(frame, face_model, pose_model)
        
        if num_faces > 0:
            total = (face_score * 0.5) + (norm_sharpness * 0.3) + (pose_score * 0.2)
        else:
            total = (pose_score * 0.6) + (norm_sharpness * 0.4)
            
        return total, sharpness, face_score, pose_score, num_faces
    else:
        # Ch·∫ø ƒë·ªô d·ª± ph√≤ng n·∫øu AI l·ªói: Ch·ªâ t√≠nh d·ª±a tr√™n ƒë·ªô n√©t
        return norm_sharpness, sharpness, 0.0, 0.0, 0

def extract_best_frames(video_path, num_frames=15, sample_rate=5):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    frame_scores = []
    
    # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë·ªÉ tr√°nh l·ªói UnboundLocalError
    face_model = None
    pose_model = None
    
    # Ch·ªâ kh·ªüi t·∫°o model n·∫øu th∆∞ vi·ªán MediaPipe kh·∫£ d·ª•ng
    if USE_AI:
        try:
            face_model = mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5)
            pose_model = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông AI Model: {e}. H·ªá th·ªëng s·∫Ω d√πng ch·∫ø ƒë·ªô qu√©t c∆° b·∫£n.")
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    count = 0
    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            if count % sample_rate == 0:
                # Truy·ªÅn c√°c model (c√≥ th·ªÉ l√† None) v√†o h√†m t√≠nh ƒëi·ªÉm
                score, sharp, face, pose, n_faces = calculate_total_score(frame, face_model, pose_model)
                
                frame_scores.append({
                    'frame': frame.copy(),
                    'score': score,
                    'timestamp': count / fps,
                    'details': f"N√©t: {sharp:.0f} | M·∫∑t: {face:.2f} | D√°ng: {pose:.2f}"
                })
                
                progress = min(count / total_frames, 1.0)
                progress_bar.progress(progress)
                status_text.text(f"‚ö° ƒêang ph√¢n t√≠ch: {count}/{total_frames} frames")

            count += 1
            if count % 150 == 0: gc.collect()
            
    finally:
        cap.release()
        # Ch·ªâ ƒë√≥ng n·∫øu model ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
        if face_model: face_model.close()
        if pose_model: pose_model.close()
        progress_bar.empty()
        status_text.empty()

    # S·∫Øp x·∫øp v√† l·ªçc c√°c frame qu√° g·∫ßn nhau (trong v√≤ng 0.8s)
    frame_scores.sort(key=lambda x: x['score'], reverse=True)
    
    final_selection = []
    for f in frame_scores:
        if not any(abs(f['timestamp'] - s['timestamp']) < 0.8 for s in final_selection):
            final_selection.append(f)
        if len(final_selection) >= num_frames: break
            
    return final_selection

# --- GIAO DI·ªÜN STREAMLIT ---

def main():
    st.set_page_config(page_title="Dance Best Frame AI", layout="wide")
    
    st.title("üï∫ AI Dance Best Frame")
    st.markdown("H·ªá th·ªëng t·ª± ƒë·ªông ch·∫•m ƒëi·ªÉm **N√©t + M·∫∑t + T∆∞ th·∫ø nh·∫£y**")

    with st.sidebar:
        st.header("‚öôÔ∏è T√πy ch·ªânh AI")
        num_frames = st.slider("S·ªë l∆∞·ª£ng ·∫£nh mu·ªën l·∫•y", 5, 30, 12)
        sample_rate = st.select_slider("ƒê·ªô chi ti·∫øt qu√©t (c√†ng th·∫•p c√†ng ch·∫≠m)", options=[2, 5, 10, 20], value=5)
        upscale = st.checkbox("T·ª± ƒë·ªông Upscale 2x (LANCZOS)", value=True)
        st.info("L∆∞u √Ω: Qu√©t chi ti·∫øt (2-5) s·∫Ω t·ªën RAM h∆°n.")

    uploaded_file = st.file_uploader("T·∫£i video c·ªßa b·∫°n l√™n", type=['mp4', 'mov', 'avi'])

    if uploaded_file:
        # T·∫°o file t·∫°m nh∆∞ng kh√¥ng t·ª± ƒë·ªông x√≥a (ƒë·ªÉ OpenCV ƒë·ªçc ƒë∆∞·ª£c)
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
            tfile.write(uploaded_file.read())
            temp_path = tfile.name # L∆∞u l·∫°i ƒë∆∞·ªùng d·∫´n

        try:
            # Th·ª±c hi·ªán x·ª≠ l√Ω
            results = extract_best_frames(temp_path, num_frames, sample_rate)
            
            if results:
                st.success(f"ƒê√£ l·ªçc ra {len(results)} kho·∫£nh kh·∫Øc ƒë·∫πp nh·∫•t!")
                
                # Hi·ªÉn th·ªã Grid (gi·ªØ nguy√™n logic hi·ªÉn th·ªã c·ªßa b·∫°n)
                cols = st.columns(3)
                for i, data in enumerate(results):
                    with cols[i % 3]:
                        img_rgb = cv2.cvtColor(data['frame'], cv2.COLOR_BGR2RGB)
                        st.image(img_rgb, caption=f"Top {i+1}")
                        
                        pil_img = Image.fromarray(img_rgb)
                        if upscale:
                            new_size = (pil_img.width * 2, pil_img.height * 2)
                            pil_img = pil_img.resize(new_size, Image.Resampling.LANCZOS)
                        
                        buf = BytesIO()
                        pil_img.save(buf, format="JPEG", quality=95)
                        st.download_button(
                            label=f"T·∫£i ·∫£nh {i+1}",
                            data=buf.getvalue(),
                            file_name=f"best_frame_{i+1}.jpg",
                            key=f"btn_{i}" # Th√™m key ƒë·ªÉ tr√°nh tr√πng l·∫∑p
                        )
        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
        finally:
            # QUAN TR·ªåNG: Gi·∫£i ph√≥ng b·ªô nh·ªõ v√† x√≥a file t·∫°m an to√†n
            gc.collect()
            if os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except PermissionError:
                    # N·∫øu v·∫´n k·∫πt, Windows s·∫Ω t·ª± x√≥a khi app ƒë√≥ng ho·∫∑c l·∫ßn ch·∫°y sau
                    pass

if __name__ == "__main__":
    main()